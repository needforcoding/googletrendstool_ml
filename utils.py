
import time
import random
import json
import pandas as pd
import os
from pytrends.request import TrendReq
from ml_model import predict_category
from datetime import datetime
import logging
import streamlit as st

logger = logging.getLogger("GoogleTrendsApp")

PROXIES_FILE = "proxies.json"
MANUAL_CATEGORIES_FILE = "manual_categories.json"
FEEDBACK_HISTORY_FILE = "feedback_history.json"

def read_json_file(filepath, default_value={}):
    """JSON dosyalarÄ±nÄ± gÃ¼venli bir ÅŸekilde okur."""
    if not os.path.exists(filepath):
        logger.warning(f"Dosya bulunamadÄ±: {filepath}. VarsayÄ±lan deÄŸer kullanÄ±lacak.")
        return default_value
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            return json.load(f)
    except (json.JSONDecodeError, IOError) as e:
        logger.error(f"{filepath} okunurken hata: {e}. VarsayÄ±lan deÄŸer kullanÄ±lacak.")
        return default_value

def load_manual_categories():
    """Manuel kategori eÅŸleÅŸtirmelerini dosyadan yÃ¼kler."""
    return read_json_file(MANUAL_CATEGORIES_FILE)

def load_proxies():
    """Proxy listesini dosyadan yÃ¼kler."""
    proxies_list = read_json_file(PROXIES_FILE, default_value=[])
    if not isinstance(proxies_list, list):
        logger.error(f"{PROXIES_FILE} iÃ§eriÄŸi bir liste olmalÄ±dÄ±r.")
        return []
    logger.info(f"{len(proxies_list)} adet proxy yÃ¼klendi.")
    return [p if p.startswith("http") else f"http://{p}" for p in proxies_list]

def get_random_proxy():
    """Mevcut proxy listesinden rastgele bir proxy seÃ§er."""
    proxies = load_proxies()
    if not proxies:
        logger.warning("Proxy listesi boÅŸ veya yÃ¼klenemedi!")
        return None
    proxy = random.choice(proxies)
    logger.info(f"SeÃ§ilen proxy: {proxy}")
    return proxy

def log_feedback_history(keyword, category):
    """KullanÄ±cÄ± geri bildirimlerini bir geÃ§miÅŸ dosyasÄ±na kaydeder."""
    try:
        history = read_json_file(FEEDBACK_HISTORY_FILE)
        
        if keyword not in history:
            history[keyword] = []

        history[keyword].append({
            "kategori": category,
            "tarih": datetime.now().isoformat()
        })

        with open(FEEDBACK_HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
            
        logger.info(f"Geri bildirim geÃ§miÅŸi gÃ¼ncellendi: {keyword} -> {category}")
    except IOError as e:
        logger.error(f"Geri bildirim geÃ§miÅŸi dosyasÄ±na yazÄ±lÄ±rken hata: {e}")

def get_trend_score(keyword, geo="TR", timeframe="today 12-m", use_proxy=False, max_retries=3, available_proxies=None):
    """
    Google Trends'den bir anahtar kelimenin ortalama trend skorunu alÄ±r.
    BaÅŸarÄ±sÄ±z proxy'leri tekrar denemez.
    """
    if use_proxy and available_proxies is None:
        available_proxies = load_proxies()

    for attempt in range(max_retries):
        proxy = None
        if use_proxy and available_proxies:
            proxy = random.choice(available_proxies)
        
        proxy_dict = {"https": proxy, "http": proxy} if proxy else None

        try:
            logger.info(
                f"[{attempt + 1}/{max_retries}] '{keyword}' iÃ§in trend verisi alÄ±nÄ±yor "
                f"(Geo: {geo}, Proxy: {proxy or 'Yok'})"
            )

            # pytrends objesini her denemede yeniden oluÅŸtur
            pytrends = TrendReq(hl="tr-TR", tz=180, timeout=(10, 25), proxies=proxy_dict, retries=2)
            pytrends.build_payload([keyword], timeframe=timeframe, geo=geo)
            df = pytrends.interest_over_time()

            if not df.empty and keyword in df.columns:
                score = round(df[keyword].mean(), 2)
                if score > 0:
                    logger.info(f"âœ… '{keyword}' iÃ§in ortalama trend skoru bulundu: {score}")
                    return score, available_proxies
                else:
                    logger.warning(f"âš ï¸ '{keyword}' iÃ§in trend skoru 0. DÃ¼ÅŸÃ¼k ilgi veya veri yok.")
                    # 0 skorunu geÃ§erli kabul et ve dÃ¶ngÃ¼den Ã§Ä±k
                    return 0.0, available_proxies
            else:
                logger.warning(f"ğŸ“‰ '{keyword}' iÃ§in Google Trends'den boÅŸ veri seti dÃ¶ndÃ¼.")
                # BoÅŸ veri seti geÃ§erli bir durum olabilir, dÃ¶ngÃ¼den Ã§Ä±k
                return 0.0, available_proxies

        except Exception as e:
            # HatalarÄ± daha spesifik yakala (Ã¶r: ConnectionError, Timeout)
            error_msg = f"âŒ '{keyword}' iÅŸlenirken hata (Proxy: {proxy}): {type(e).__name__} - {e}"
            logger.error(error_msg)
            
            # HatayÄ± Streamlit arayÃ¼zÃ¼nde gÃ¶ster
            if "trend_errors" in st.session_state:
                st.session_state.trend_errors.append(error_msg)

            # BaÅŸarÄ±sÄ±z olan proxy'yi listeden kaldÄ±r
            if use_proxy and proxy and available_proxies:
                available_proxies.remove(proxy)
                logger.info(f"Proxy {proxy} baÅŸarÄ±sÄ±z olduÄŸu iÃ§in listeden kaldÄ±rÄ±ldÄ±.")

            # Son deneme deÄŸilse bekle
            if attempt < max_retries - 1:
                wait_time = random.uniform(3, 7)
                logger.info(f" yeniden denemeden Ã¶nce {wait_time:.1f} saniye bekleniyor...")
                time.sleep(wait_time)

    logger.error(f"ğŸš¨ '{keyword}' iÃ§in trend skoru tÃ¼m denemeler sonunda alÄ±namadÄ±.")
    return 0.0, available_proxies

def analyze_keywords(keywords, geo="TR", timeframe="today 12-m", manual_map={}, use_proxy=False):
    """Verilen anahtar kelime listesini analiz eder, trend skorlarÄ±nÄ± ve kategorilerini bulur."""
    logger.info(f"Analiz baÅŸlÄ±yor: {len(keywords)} anahtar kelime, Ãœlke: {geo}, Zaman: {timeframe}, Proxy: {use_proxy}")
    results = []
    
    # Proxy kullanÄ±lacaksa, proxy listesini bir kere yÃ¼kle
    available_proxies = load_proxies() if use_proxy else None

    with st.spinner(f"{len(keywords)} anahtar kelime analiz ediliyor..."):
        for i, kw in enumerate(keywords):
            st.info(f"[{i+1}/{len(keywords)}] '{kw}' analiz ediliyor...")

            score, updated_proxies = get_trend_score(
                kw,
                geo=geo,
                timeframe=timeframe,
                use_proxy=use_proxy,
                available_proxies=available_proxies
            )

            # Proxy listesini gÃ¼ncelle
            if use_proxy:
                available_proxies = updated_proxies

            category = manual_map.get(kw, predict_category(kw))

            results.append({
                "Kelime": kw,
                "Kategori": category,
                "Ãœlke": geo,
                "Zaman AralÄ±ÄŸÄ±": timeframe,
                "Trend Skoru": score
            })

            if i < len(keywords) - 1:
                wait_time = random.uniform(2, 5)
                logger.info(f"Rate limit'e takÄ±lmamak iÃ§in {wait_time:.1f} saniye bekleniyor.")
                time.sleep(wait_time)

    logger.info("Analiz tamamlandÄ±.")
    return pd.DataFrame(results)

